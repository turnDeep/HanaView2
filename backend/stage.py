#!/usr/bin/env python3
â€œâ€â€
çµ±åˆæ ªå¼åˆ†æã‚·ã‚¹ãƒ†ãƒ  - All-in-Oneç‰ˆ
ãƒ†ã‚£ãƒƒã‚«ãƒ¼å–å¾— â†’ ãƒ‡ãƒ¼ã‚¿åˆ†æ â†’ ã‚¹ãƒ†ãƒ¼ã‚¸åˆ¤å®š â†’ ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆ

ç‰¹å¾´:

- ä¸¦åˆ—å‡¦ç†ã«ã‚ˆã‚‹é«˜é€ŸåŒ–
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—è¡¨ç¤º
- Web APIå¯¾å¿œ
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
  â€œâ€â€

import pandas as pd
import numpy as np
import yfinance as yf
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from curl_cffi.requests import Session
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed
from dataclasses import dataclass, asdict
from typing import Optional, Dict, List, Tuple
import pandas_ta as ta
from datetime import datetime
import json
import os
import logging
from tqdm import tqdm
import warnings
warnings.filterwarnings(â€˜ignoreâ€™)

# ============================================================================

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š

# ============================================================================

logging.basicConfig(
level=logging.INFO,
format=â€™%(asctime)s - %(levelname)s - %(message)sâ€™,
handlers=[
logging.FileHandler(â€˜stock_analyzer.logâ€™),
logging.StreamHandler()
]
)
logger = logging.getLogger(**name**)

# ============================================================================

# ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹å®šç¾©

# ============================================================================

@dataclass
class AnalysisResult:
â€œâ€â€œåˆ†æçµæœã‚’æ ¼ç´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹â€â€â€
ticker: str
current_stage: int
stage_name: str
stage_start_date: str
score: int
judgment: str
action: str
latest_price: float
ma50: float
rs_rating: float
atr_multiple: float
success: bool
error_message: Optional[str] = None

# ============================================================================

# 1. ãƒ†ã‚£ãƒƒã‚«ãƒ¼å–å¾—

# ============================================================================

def fetch_nasdaq_nyse_tickers() -> List[str]:
â€œâ€â€œNASDAQã¨NYSEã®ãƒ†ã‚£ãƒƒã‚«ãƒ¼ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°â€â€â€
logger.info(â€œğŸ“¥ ãƒ†ã‚£ãƒƒã‚«ãƒ¼ãƒªã‚¹ãƒˆã‚’å–å¾—ä¸­â€¦â€)

```
nasdaq_url = "https://datahub.io/core/nasdaq-listings/_r/-/data/nasdaq-listed-symbols.csv"
nyse_url = "https://datahub.io/core/nyse-other-listings/_r/-/data/nyse-listed.csv"

try:
    # NASDAQ
    nasdaq_df = pd.read_csv(nasdaq_url)
    nasdaq_df.dropna(subset=['Symbol'], inplace=True)
    nasdaq_tickers = nasdaq_df['Symbol'].astype(str).tolist()
    
    # NYSE
    nyse_df = pd.read_csv(nyse_url)
    nyse_df.dropna(subset=['ACT Symbol'], inplace=True)
    nyse_tickers = nyse_df['ACT Symbol'].astype(str).tolist()
    
    # çµåˆãƒ»é‡è¤‡å‰Šé™¤
    all_tickers = sorted(list(set(nasdaq_tickers + nyse_tickers)))
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    excluded_suffixes = ['.U', '.W', '.A', '.B']
    filtered = [t for t in all_tickers 
               if len(t) != 5 
               and not any(s in t for s in excluded_suffixes)
               and '$' not in t]
    
    logger.info(f"âœ… {len(filtered)} ä»¶ã®ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’å–å¾—")
    return filtered
    
except Exception as e:
    logger.error(f"âŒ ãƒ†ã‚£ãƒƒã‚«ãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    return []
```

# ============================================================================

# 2. ãƒ‡ãƒ¼ã‚¿å–å¾—

# ============================================================================

def fetch_stock_data(ticker: str, period: str = â€œ2yâ€) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
â€œâ€â€œæ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—â€â€â€
session = Session(impersonate=â€œchrome110â€)

```
try:
    data = yf.download(
        tickers=[ticker, "SPY"],
        period=period,
        session=session,
        progress=False
    )
    
    if data.empty or ticker not in data.columns.get_level_values(1):
        return None, None
    
    stock_data = data.xs(ticker, level=1, axis=1).copy()
    benchmark_data = data.xs("SPY", level=1, axis=1).copy()
    
    stock_data.dropna(inplace=True)
    benchmark_data.dropna(inplace=True)
    
    if stock_data.empty:
        return None, None
        
    return stock_data, benchmark_data
    
except Exception as e:
    logger.debug(f"{ticker}: ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼ - {e}")
    return None, None
```

# ============================================================================

# 3. ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™è¨ˆç®—

# ============================================================================

def calculate_ma_slope(series: pd.Series, period: int = 10) -> float:
â€œâ€â€œç§»å‹•å¹³å‡ç·šã®å‚¾ãã‚’è¨ˆç®—â€â€â€
if len(series) < period:
return 0.0

```
y = series.tail(period).values
y_normalized = y / np.linalg.norm(y)
x = np.arange(len(y_normalized))

slope = np.polyfit(x, y_normalized, 1)[0]
return slope
```

def calculate_rs_rating(stock_data: pd.DataFrame, benchmark_data: pd.DataFrame) -> pd.Series:
â€œâ€â€œç›¸å¯¾å¼·åº¦(RS Rating)ã‚’è¨ˆç®—â€â€â€
common_index = stock_data.index.intersection(benchmark_data.index)
_stock = stock_data.loc[common_index]
_benchmark = benchmark_data.loc[common_index]

```
rs_line = (_stock['Close'] / _benchmark['Close'])

rs_rating = rs_line.rolling(window=252, min_periods=50).apply(
    lambda x: pd.Series(x).rank(pct=True).iloc[-1] * 100, raw=False
)
return rs_rating.fillna(0)
```

def calculate_indicators(stock_data: pd.DataFrame, benchmark_data: pd.DataFrame) -> pd.DataFrame:
â€œâ€â€œå…¨ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã‚’è¨ˆç®—â€â€â€
df = stock_data.copy()

```
# ç§»å‹•å¹³å‡
df['ma50'] = ta.sma(df['Close'], length=50)
df['ma200'] = ta.sma(df['Close'], length=200)
df['volume_ma50'] = ta.sma(df['Volume'], length=50)

# MAå‚¾ã
df['ma50_slope'] = df['ma50'].rolling(window=10).apply(
    lambda x: calculate_ma_slope(pd.Series(x), period=10), raw=False
)
df['ma50_slope'] = df['ma50_slope'].fillna(0)

# VWAP
df['vwap'] = ta.vwap(high=df['High'], low=df['Low'], close=df['Close'], volume=df['Volume'])
df['vwap_slope'] = df['vwap'].rolling(window=10).apply(
    lambda x: calculate_ma_slope(pd.Series(x), period=10), raw=False
)
df['vwap_slope'] = df['vwap_slope'].fillna(0)

# RS Rating
df['rs_rating'] = calculate_rs_rating(df, benchmark_data)
df['rs_rating_ma10'] = ta.sma(df['rs_rating'], length=10)

# ATR
df['atr'] = ta.atr(df['High'], df['Low'], df['Close'], length=14)
df['atr_ma_distance_multiple'] = np.where(
    df['atr'] > 0,
    abs(df['Close'] - df['ma50']) / df['atr'],
    0
)

df.dropna(inplace=True)
return df
```

# ============================================================================

# 4. ã‚¹ãƒ†ãƒ¼ã‚¸åˆ†æã‚¨ãƒ³ã‚¸ãƒ³

# ============================================================================

class StageAnalyzer:
â€œâ€â€œã‚¹ãƒ†ãƒ¼ã‚¸åˆ†æã‚¯ãƒ©ã‚¹â€â€â€

```
def __init__(self, indicators_df: pd.DataFrame, ticker: str, benchmark_indicators_df: pd.DataFrame):
    self.indicators_df = indicators_df
    self.ticker = ticker
    self.benchmark_indicators_df = benchmark_indicators_df
    self.latest_data = indicators_df.iloc[-1]
    self.latest_benchmark_data = benchmark_indicators_df.iloc[-1]
    self.analysis_date = self.latest_data.name.strftime('%Y-%m-%d')

def determine_current_stage(self) -> int:
    """ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã‚’åˆ¤å®š"""
    ma50_slope = self.latest_data['ma50_slope']
    slope_threshold = 0.0015
    
    # ã‚¹ãƒ†ãƒ¼ã‚¸4ï¼ˆä¸‹é™ï¼‰
    if ma50_slope < -slope_threshold:
        return 4
    
    # ã‚¹ãƒ†ãƒ¼ã‚¸2ï¼ˆä¸Šæ˜‡ï¼‰
    if ma50_slope > slope_threshold:
        transition_details = self.score_stage1_to_2()
        score = transition_details.get('score', 0)
        level = transition_details.get('level', 'Cåˆ¤å®š')
        
        if score >= 80 or level.startswith('A') or level.startswith('B'):
            return 2
    
    # ã‚¹ãƒ†ãƒ¼ã‚¸1 or 3
    price = self.latest_data['Close']
    history_1y = self.indicators_df.iloc[-252:-1]
    history_150d = self.indicators_df.iloc[-151:-1]
    
    if history_1y.empty or len(history_1y) < 200:
        return 1
    
    high_1y = history_1y['High'].max()
    high_150d = history_150d['High'].max() if not history_150d.empty else high_1y
    
    if price < high_1y * 0.6:
        return 1
    
    if price >= high_150d * 0.7:
        return 3
    
    return 1

def score_stage1_to_2(self) -> Dict:
    """ã‚¹ãƒ†ãƒ¼ã‚¸1â†’2ã®ã‚¹ã‚³ã‚¢è¨ˆç®—"""
    score = 0
    details = {}
    
    # 1. å‡ºæ¥é«˜
    volume_ratio = self.latest_data['Volume'] / self.latest_data['volume_ma50']
    if volume_ratio >= 2.5:
        score += 20
        details['å‡ºæ¥é«˜'] = f"Aè©•ä¾¡ ({volume_ratio:.1f}å€)"
    elif volume_ratio >= 2.0:
        score += 15
        details['å‡ºæ¥é«˜'] = f"Bè©•ä¾¡ ({volume_ratio:.1f}å€)"
    
    # 2. ä¾¡æ ¼ãƒ–ãƒ¬ã‚¤ã‚¯
    price_50day_high = self.indicators_df['Close'].tail(51).iloc[:-1].max()
    current_close = self.latest_data['Close']
    if current_close > price_50day_high * 1.03:
        score += 25
        details['ä¾¡æ ¼ãƒ–ãƒ¬ã‚¤ã‚¯'] = "Aè©•ä¾¡"
    elif current_close > price_50day_high:
        score += 20
        details['ä¾¡æ ¼ãƒ–ãƒ¬ã‚¤ã‚¯'] = "Bè©•ä¾¡"
    
    # 3. MAè»¢æ›
    price_over_ma50 = self.latest_data['Close'] > self.latest_data['ma50']
    ma50_slope_up = self.latest_data['ma50_slope'] > 0.002
    if price_over_ma50 and ma50_slope_up:
        score += 20
        details['MAè»¢æ›'] = "Aè©•ä¾¡"
    elif price_over_ma50 or ma50_slope_up:
        score += 10
        details['MAè»¢æ›'] = "Bè©•ä¾¡"
    
    # 4. RS Rating
    rs = self.latest_data['rs_rating']
    if rs >= 85:
        score += 15
        details['RS Rating'] = f"Aè©•ä¾¡ ({rs:.0f})"
    elif rs >= 70:
        score += 10
        details['RS Rating'] = f"Bè©•ä¾¡ ({rs:.0f})"
    
    # 5. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
    atr_multiple = self.latest_data['atr_ma_distance_multiple']
    if 2.0 <= atr_multiple < 4.0:
        score += 15
        details['ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£'] = "Aè©•ä¾¡"
    elif 1.0 <= atr_multiple < 2.0:
        score += 10
        details['ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£'] = "Bè©•ä¾¡"
    
    # 6. å¸‚å ´ç’°å¢ƒ
    is_bull_market = self.latest_benchmark_data['Close'] > self.latest_benchmark_data['ma200']
    if is_bull_market:
        score += 5
        details['å¸‚å ´ç’°å¢ƒ'] = "å¼·æ°—"
    
    # ç¢ºèªãƒ¡ã‚«ãƒ‹ã‚ºãƒ 
    is_confirmed = False
    for i in range(1, 16):
        if len(self.indicators_df) < (50 + i + 1):
            continue
        
        breakout_day_index = -(i)
        breakout_day_data = self.indicators_df.iloc[breakout_day_index]
        historical_data = self.indicators_df.iloc[breakout_day_index - 50 : breakout_day_index]
        
        if historical_data.empty:
            continue
        
        price_50d_high_before = historical_data['Close'].max()
        
        if breakout_day_data['Close'] > price_50d_high_before:
            days_since = i - 1
            
            if days_since >= 2:
                days_to_confirm_df = self.indicators_df.iloc[-days_since:]
                days_above = (days_to_confirm_df['Close'] > price_50d_high_before * 0.98).sum()
                total_days = len(days_to_confirm_df)
                
                if days_above / total_days >= 0.8:
                    is_confirmed = True
                    break
    
    # åˆ¤å®š
    if score >= 85:
        level = "Aåˆ¤å®š (å¼·åŠ›ãªç§»è¡Œã‚·ã‚°ãƒŠãƒ«)"
        action = "è‡ªä¿¡ã‚’æŒã£ã¦ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’æ¤œè¨ã™ã‚‹ã¹ãç†æƒ³çš„ãªãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã€‚"
    elif is_confirmed and score >= 70:
        level = "Båˆ¤å®š (ç§»è¡Œã‚·ã‚°ãƒŠãƒ«)"
        action = "ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’æ¤œè¨ã€‚ãƒªã‚¹ã‚¯ç®¡ç†ã®ãŸã‚ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚ºèª¿æ•´ã‚‚è€ƒæ…®ã€‚"
    elif score >= 75 and not is_confirmed:
        level = "B-åˆ¤å®š (æœ‰æœ›ã ãŒç¢ºèªå¾…ã¡)"
        action = f"é«˜ã‚¹ã‚³ã‚¢({score}ç‚¹)ã ãŒæœªç¢ºèªã€‚æ…é‡ã«ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ¤œè¨ã€‚"
    else:
        level = "Cåˆ¤å®š (æº–å‚™æ®µéš)"
        action = f"ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã¯è¦‹é€ã‚Šã€å…¨ã¦ã®æ¡ä»¶ãŒæƒã†ã®ã‚’å¾…ã¤ (ã‚¹ã‚³ã‚¢: {score})ã€‚"
    
    return {"score": score, "level": level, "action": action, "details": details}

def score_stage2_to_3(self) -> Dict:
    """ã‚¹ãƒ†ãƒ¼ã‚¸2â†’3ã®ã‚¹ã‚³ã‚¢è¨ˆç®—"""
    score = 0
    
    # éç†±æ„Ÿ
    atr_multiple = self.latest_data['atr_ma_distance_multiple']
    if atr_multiple >= 7.0:
        score += 30
    elif atr_multiple >= 5.0:
        score += 15
    
    # å¤§å£ã®å£²ã‚Š
    recent_data = self.indicators_df.tail(20)
    down_days_high_volume = recent_data[
        (recent_data['Close'] < recent_data['Close'].shift(1)) & 
        (recent_data['Volume'] > recent_data['volume_ma50'] * 1.5)
    ]
    if len(down_days_high_volume) >= 2:
        score += 25
    elif len(down_days_high_volume) == 1:
        score += 10
    
    # ä¸Šãƒ’ã‚²
    upper_wick = self.indicators_df['High'] - self.indicators_df[['Open', 'Close']].max(axis=1)
    is_long_wick = (upper_wick.tail(5) > (self.indicators_df['High'] - self.indicators_df['Low']).tail(5) * 0.5).any()
    if is_long_wick:
        score += 20
    
    # MAå¹³å¦åŒ–
    if abs(self.latest_data['ma50_slope']) < 0.001:
        score += 15
    
    # RSä½ä¸‹
    if self.latest_data['rs_rating'] < self.latest_data['rs_rating_ma10']:
        score += 10
    
    # åˆ¤å®š
    if score >= 75:
        level = "å±é™º (ã‚¹ãƒ†ãƒ¼ã‚¸3ç§»è¡ŒãŒæ¿ƒåš)"
        action = "ãƒã‚¸ã‚·ãƒ§ãƒ³ã®å¤§éƒ¨åˆ†ã®åˆ©ç›Šç¢ºå®šã‚’å¼·ãæ¨å¥¨ã€‚"
    elif score >= 50:
        level = "è­¦å‘Š (ãƒˆãƒ¬ãƒ³ãƒ‰éˆåŒ–)"
        action = "æ–°è¦ã®è²·ã„ã¯è¦‹é€ã‚Šã€ä¸€éƒ¨ã‚’åˆ©ç›Šç¢ºå®šã€‚"
    else:
        level = "å®‰å…¨ (ã‚¹ãƒ†ãƒ¼ã‚¸2ç¶™ç¶š)"
        action = "ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚’ç¶­æŒã—ã€ãƒˆãƒ¬ãƒ³ãƒ‰ã®ç¶™ç¶šã‚’æœŸå¾…ã™ã‚‹ã€‚"
    
    return {"score": score, "level": level, "action": action}

def analyze(self) -> Dict:
    """å®Œå…¨ãªåˆ†æã‚’å®Ÿè¡Œ"""
    current_stage = self.determine_current_stage()
    
    if current_stage == 1:
        transition_analysis = self.score_stage1_to_2()
        transition_analysis['target_transition'] = "ã‚¹ãƒ†ãƒ¼ã‚¸1 â†’ 2"
    elif current_stage == 2:
        transition_analysis = self.score_stage2_to_3()
        transition_analysis['target_transition'] = "ã‚¹ãƒ†ãƒ¼ã‚¸2 â†’ 3"
    else:
        transition_analysis = {"score": 0, "level": "N/A", "action": "N/A", "target_transition": f"ã‚¹ãƒ†ãƒ¼ã‚¸{current_stage}"}
    
    return {
        "ticker": self.ticker,
        "analysis_date": self.analysis_date,
        "current_stage": f"ã‚¹ãƒ†ãƒ¼ã‚¸{current_stage}",
        "transition_analysis": transition_analysis
    }
```

# ============================================================================

# 5. ã‚¹ãƒ†ãƒ¼ã‚¸é–‹å§‹æ—¥æ¤œå‡º

# ============================================================================

def find_stage_start_date(ticker: str, stock_indicators: pd.DataFrame,
benchmark_indicators: pd.DataFrame, current_stage: int) -> str:
â€œâ€â€œç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã®é–‹å§‹æ—¥ã‚’ç‰¹å®šâ€â€â€
for i in range(1, len(stock_indicators)):
date_to_check_index = -i - 1
if abs(date_to_check_index) > len(stock_indicators) or len(stock_indicators.iloc[:date_to_check_index]) < 252:
break

```
    historical_stock_slice = stock_indicators.iloc[:date_to_check_index]
    historical_benchmark_slice = benchmark_indicators.loc[historical_stock_slice.index]
    
    try:
        analyzer = StageAnalyzer(historical_stock_slice, ticker, historical_benchmark_slice)
        stage = analyzer.determine_current_stage()
        if stage != current_stage:
            start_date = stock_indicators.index[date_to_check_index + 1]
            return start_date.strftime('%Y-%m-%d')
    except:
        continue

return stock_indicators.index[0].strftime('%Y-%m-%d')
```

# ============================================================================

# 6. ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆ

# ============================================================================

def create_chart_json(ticker: str, df: pd.DataFrame, stage_history: Optional[pd.DataFrame] = None) -> Dict:
â€œâ€â€œWebè¡¨ç¤ºç”¨ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ£ãƒ¼ãƒˆã‚’JSONå½¢å¼ã§ç”Ÿæˆâ€â€â€
try:
fig = make_subplots(
rows=4, cols=1,
shared_xaxes=True,
vertical_spacing=0.02,
row_heights=[0.5, 0.15, 0.15, 0.2],
subplot_titles=(
fâ€™{ticker} - æ ªä¾¡ãƒãƒ£ãƒ¼ãƒˆï¼ˆã‚¹ãƒ†ãƒ¼ã‚¸åˆ†æï¼‰â€™,
â€˜å‡ºæ¥é«˜â€™,
â€˜RS Ratingï¼ˆç›¸å¯¾å¼·åº¦ï¼‰â€™,
â€˜ATR & MAä¹–é›¢ç‡â€™
)
)

```
    # ã‚¹ãƒ†ãƒ¼ã‚¸èƒŒæ™¯è‰²
    if stage_history is not None and not stage_history.empty:
        stage_colors = {1: 'rgba(0,255,0,0.1)', 2: 'rgba(0,255,0,0.2)', 
                      3: 'rgba(255,165,0,0.15)', 4: 'rgba(255,0,0,0.15)'}
        
        current_stage = None
        start_date = None
        
        for _, row in stage_history.iterrows():
            if current_stage != row['stage']:
                if current_stage is not None:
                    fig.add_vrect(
                        x0=start_date, x1=row['date'],
                        fillcolor=stage_colors.get(current_stage, 'rgba(128,128,128,0.1)'),
                        layer="below", line_width=0, row=1, col=1,
                        annotation_text=f"S{current_stage}",
                        annotation_position="top left"
                    )
                current_stage = row['stage']
                start_date = row['date']
        
        if current_stage is not None:
            fig.add_vrect(
                x0=start_date, x1=df.index[-1],
                fillcolor=stage_colors.get(current_stage, 'rgba(128,128,128,0.1)'),
                layer="below", line_width=0, row=1, col=1,
                annotation_text=f"S{current_stage}",
                annotation_position="top left"
            )
    
    # 1. ãƒ­ãƒ¼ã‚½ã‚¯è¶³
    fig.add_trace(
        go.Candlestick(
            x=df.index.strftime('%Y-%m-%d').tolist(),
            open=df['Open'], high=df['High'],
            low=df['Low'], close=df['Close'],
            name='OHLC',
            increasing_line_color='#26a69a',
            decreasing_line_color='#ef5350'
        ),
        row=1, col=1
    )
    
    # 2. ç§»å‹•å¹³å‡ç·š
    fig.add_trace(go.Scatter(
        x=df.index.strftime('%Y-%m-%d').tolist(), y=df['ma50'], 
        mode='lines', name='MA50', line=dict(color='orange', width=2)),
        row=1, col=1)
    
    fig.add_trace(go.Scatter(
        x=df.index.strftime('%Y-%m-%d').tolist(), y=df['ma200'],
        mode='lines', name='MA200', line=dict(color='blue', width=2)),
        row=1, col=1)
    
    if 'vwap' in df.columns:
        fig.add_trace(go.Scatter(
            x=df.index.strftime('%Y-%m-%d').tolist(), y=df['vwap'],
            mode='lines', name='VWAP', line=dict(color='green', width=1.5)),
            row=1, col=1)
    
    # 3. å‡ºæ¥é«˜
    colors = ['#ef5350' if df['Close'].iloc[i] < df['Open'].iloc[i] else '#26a69a'
              for i in range(len(df))]
    
    fig.add_trace(go.Bar(
        x=df.index.strftime('%Y-%m-%d').tolist(), y=df['Volume'],
        name='å‡ºæ¥é«˜', marker_color=colors, opacity=0.7),
        row=2, col=1)
    
    if 'volume_ma50' in df.columns:
        fig.add_trace(go.Scatter(
            x=df.index.strftime('%Y-%m-%d').tolist(), y=df['volume_ma50'],
            mode='lines', name='å‡ºæ¥é«˜MA50', line=dict(color='purple', width=2)),
            row=2, col=1)
    
    # 4. RS Rating
    if 'rs_rating' in df.columns:
        fig.add_trace(go.Scatter(
            x=df.index.strftime('%Y-%m-%d').tolist(), y=df['rs_rating'],
            mode='lines', name='RS Rating', line=dict(color='blue', width=2),
            fill='tozeroy', fillcolor='rgba(0,100,255,0.1)'),
            row=3, col=1)
        
        if 'rs_rating_ma10' in df.columns:
            fig.add_trace(go.Scatter(
                x=df.index.strftime('%Y-%m-%d').tolist(), y=df['rs_rating_ma10'],
                mode='lines', name='RS MA10', line=dict(color='orange', width=1.5, dash='dash')),
                row=3, col=1)
        
        # åŸºæº–ç·š
        fig.add_hline(y=85, line_dash="dot", line_color="green", 
                     annotation_text="å¼·ã„(85)", row=3, col=1, opacity=0.6)
        fig.add_hline(y=70, line_dash="dot", line_color="lightgreen",
                     annotation_text="è‰¯ã„(70)", row=3, col=1, opacity=0.6)
        fig.add_hline(y=50, line_dash="dot", line_color="gray",
                     annotation_text="ä¸­ç«‹(50)", row=3, col=1, opacity=0.6)
    
    # 5. ATR
    if 'atr' in df.columns:
        fig.add_trace(go.Scatter(
            x=df.index.strftime('%Y-%m-%d').tolist(), y=df['atr'],
            mode='lines', name='ATR', line=dict(color='purple', width=2)),
            row=4, col=1)
    
    if 'atr_ma_distance_multiple' in df.columns:
        fig.add_trace(go.Scatter(
            x=df.index.strftime('%Y-%m-%d').tolist(), y=df['atr_ma_distance_multiple'],
            mode='lines', name='MAä¹–é›¢ç‡(ATRå€)', line=dict(color='red', width=2)),
            row=4, col=1)
        
        fig.add_hline(y=5, line_dash="dash", line_color="red",
                     annotation_text="éç†±(5.0x)", row=4, col=1)
    
    # çµ±è¨ˆæƒ…å ±
    latest = df.iloc[-1]
    stats_text = f"""<b>æœ€æ–°ãƒ‡ãƒ¼ã‚¿ ({latest.name.strftime('%Y-%m-%d')})</b><br>
```

çµ‚å€¤: <b>${latest[â€˜Closeâ€™]:.2f}</b><br>
MA50: ${latest[â€˜ma50â€™]:.2f} ({((latest[â€˜Closeâ€™]/latest[â€˜ma50â€™]-1)*100):+.1f}%)<br>
RS Rating: {latest.get(â€˜rs_ratingâ€™, 0):.0f}/100<br>
ATRå€ç‡: {latest.get(â€˜atr_ma_distance_multipleâ€™, 0):.2f}xâ€â€â€

```
    fig.add_annotation(
        text=stats_text,
        xref="paper", yref="paper",
        x=0.02, y=0.98,
        showarrow=False,
        bgcolor="rgba(255,255,255,0.95)",
        bordercolor="black",
        borderwidth=2,
        align="left",
        font=dict(size=12)
    )
    
    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
    fig.update_layout(
        title={
            'text': f'<b>{ticker}</b> - ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æãƒãƒ£ãƒ¼ãƒˆ',
            'x': 0.5,
            'xanchor': 'center',
            'font': {'size': 20, 'color': '#1f77b4'}
        },
        xaxis_rangeslider_visible=False,
        height=900,
        showlegend=True,
        hovermode='x unified',
        template='plotly_white',
        font=dict(family="Arial, sans-serif", size=11)
    )
    
    # Yè»¸è¨­å®š
    fig.update_yaxes(title_text="ä¾¡æ ¼ (USD)", row=1, col=1)
    fig.update_yaxes(title_text="å‡ºæ¥é«˜", row=2, col=1)
    fig.update_yaxes(title_text="RS Rating", row=3, col=1)
    fig.update_yaxes(title_text="ATR / ä¹–é›¢ç‡", row=4, col=1)
    
    # JSONå½¢å¼ã§è¿”ã™
    return json.loads(fig.to_json())
    
except Exception as e:
    logger.error(f"{ticker}: ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼ - {e}")
    return None
```

# ============================================================================

# 7. å˜ä¸€ãƒ†ã‚£ãƒƒã‚«ãƒ¼åˆ†æï¼ˆä¸¦åˆ—å‡¦ç†ç”¨ï¼‰

# ============================================================================

def analyze_single_ticker(ticker: str, benchmark_df: pd.DataFrame,
benchmark_indicators: pd.DataFrame,
generate_chart: bool = False,
output_dir: str = â€˜stage1or2â€™) -> Optional[AnalysisResult]:
â€œâ€â€œå˜ä¸€ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã®å®Œå…¨ãªåˆ†æâ€â€â€
try:
# ãƒ‡ãƒ¼ã‚¿å–å¾—
stock_df, _ = fetch_stock_data(ticker, period=â€œ2yâ€)

```
    if stock_df is None or len(stock_df) < 252:
        return None
    
    # æŒ‡æ¨™è¨ˆç®—
    stock_indicators = calculate_indicators(stock_df, benchmark_df)
    
    if stock_indicators.empty:
        return None
    
    # ã‚¹ãƒ†ãƒ¼ã‚¸åˆ†æ
    analyzer = StageAnalyzer(stock_indicators, ticker, benchmark_indicators)
    analysis = analyzer.analyze()
    
    current_stage_str = analysis['current_stage']
    current_stage_num = int(current_stage_str.replace('ã‚¹ãƒ†ãƒ¼ã‚¸', ''))
    
    transition_analysis = analysis['transition_analysis']
    score = transition_analysis.get('score', 0)
    level = transition_analysis.get('level', 'N/A')
    action = transition_analysis.get('action', 'N/A')
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶
    is_stage1_candidate = (current_stage_num == 1 and score >= 50)
    is_stage2 = (current_stage_num == 2)
    
    if not (is_stage1_candidate or is_stage2):
        return None
    
    # ã‚¹ãƒ†ãƒ¼ã‚¸é–‹å§‹æ—¥
    stage_start_date = find_stage_start_date(
        ticker, stock_indicators, benchmark_indicators, current_stage_num
    )
    
    # æœ€æ–°ãƒ‡ãƒ¼ã‚¿
    latest = stock_indicators.iloc[-1]
    
    # ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if generate_chart:
        chart_path = os.path.join(output_dir, f'{ticker}_chart.png')
        create_chart_image(ticker, stock_indicators, chart_path)
    
    # çµæœã‚’è¿”ã™
    stage_names = {
        1: 'åº•å›ºã‚æœŸ',
        2: 'ä¸Šæ˜‡æœŸ',
        3: 'å¤©äº•åœ',
        4: 'ä¸‹é™æœŸ'
    }
    
    return AnalysisResult(
        ticker=ticker,
        current_stage=current_stage_num,
        stage_name=stage_names.get(current_stage_num, 'N/A'),
        stage_start_date=stage_start_date,
        score=score,
        judgment=level,
        action=action,
        latest_price=float(latest['Close']),
        ma50=float(latest['ma50']),
        rs_rating=float(latest['rs_rating']),
        atr_multiple=float(latest['atr_ma_distance_multiple']),
        success=True
    )
    
except Exception as e:
    logger.debug(f"{ticker}: åˆ†æã‚¨ãƒ©ãƒ¼ - {e}")
    return None
```

# ============================================================================

# 8. ãƒ¡ã‚¤ãƒ³åˆ†æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆä¸¦åˆ—å‡¦ç†ï¼‰

# ============================================================================

def run_full_analysis(
use_existing_tickers: bool = False,
ticker_file: str = â€˜stock.csvâ€™,
max_tickers: Optional[int] = None,
max_workers: int = 4,
generate_charts: bool = False,
output_dir: str = â€˜stage1or2â€™,
output_csv: str = â€˜stage1or2.csvâ€™
) -> Tuple[pd.DataFrame, List[AnalysisResult]]:
â€œâ€â€
å®Œå…¨ãªåˆ†æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œ

```
Args:
    use_existing_tickers: æ—¢å­˜ã®stock.csvã‚’ä½¿ç”¨ã™ã‚‹ã‹
    ticker_file: ãƒ†ã‚£ãƒƒã‚«ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    max_tickers: å‡¦ç†ã™ã‚‹æœ€å¤§ãƒ†ã‚£ãƒƒã‚«ãƒ¼æ•°
    max_workers: ä¸¦åˆ—å‡¦ç†ã®ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°
    generate_charts: ãƒãƒ£ãƒ¼ãƒˆç”»åƒã‚’ç”Ÿæˆã™ã‚‹ã‹
    output_dir: ãƒãƒ£ãƒ¼ãƒˆå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    output_csv: çµæœCSVå‡ºåŠ›ãƒ‘ã‚¹

Returns:
    (DataFrame, List[AnalysisResult]): çµæœã®DataFrameã¨AnalysisResultãƒªã‚¹ãƒˆ
"""

logger.info("="*70)
logger.info("ğŸš€ çµ±åˆæ ªå¼åˆ†æã‚·ã‚¹ãƒ†ãƒ ã‚’é–‹å§‹")
logger.info("="*70)

# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
if generate_charts:
    os.makedirs(output_dir, exist_ok=True)

# ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ†ã‚£ãƒƒã‚«ãƒ¼å–å¾—
if use_existing_tickers and os.path.exists(ticker_file):
    logger.info(f"ğŸ“‚ æ—¢å­˜ã®{ticker_file}ã‹ã‚‰ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’èª­ã¿è¾¼ã¿")
    with open(ticker_file, 'r', encoding='utf-8-sig') as f:
        tickers = [line.strip() for line in f if line.strip()]
else:
    logger.info("ğŸŒ NASDAQ/NYSEã‹ã‚‰ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    tickers = fetch_nasdaq_nyse_tickers()
    
    # stock.csvã«ä¿å­˜
    with open(ticker_file, 'w') as f:
        for ticker in tickers:
            f.write(f"{ticker}\n")
    logger.info(f"ğŸ’¾ {ticker_file}ã«ä¿å­˜å®Œäº†")

if max_tickers:
    tickers = tickers[:max_tickers]
    logger.info(f"ğŸ”¢ å…ˆé ­{max_tickers}éŠ˜æŸ„ã®ã¿å‡¦ç†")

logger.info(f"ğŸ“Š åˆè¨ˆ {len(tickers)} éŠ˜æŸ„ã‚’åˆ†æäºˆå®š")

# ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿å–å¾—
logger.info("\nğŸ”„ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿(SPY)ã‚’å–å¾—ä¸­...")
benchmark_df, _ = fetch_stock_data("SPY", period="2y")

if benchmark_df is None:
    logger.error("âŒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—")
    return pd.DataFrame(), []

benchmark_indicators = calculate_indicators(benchmark_df, benchmark_df.copy())
logger.info("âœ… ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†")

# ã‚¹ãƒ†ãƒƒãƒ—3: ä¸¦åˆ—å‡¦ç†ã§å…¨ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’åˆ†æ
logger.info(f"\nâš¡ {max_workers}ä¸¦åˆ—ã§åˆ†æé–‹å§‹...")

results = []

with ThreadPoolExecutor(max_workers=max_workers) as executor:
    # ã‚¸ãƒ§ãƒ–ã‚’æŠ•å…¥
    future_to_ticker = {
        executor.submit(
            analyze_single_ticker,
            ticker,
            benchmark_df,
            benchmark_indicators,
            generate_charts,
            output_dir
        ): ticker
        for ticker in tickers
    }
    
    # é€²æ—ãƒãƒ¼ä»˜ãã§çµæœã‚’åé›†
    with tqdm(total=len(tickers), desc="åˆ†æé€²æ—", unit="éŠ˜æŸ„") as pbar:
        for future in as_completed(future_to_ticker):
            ticker = future_to_ticker[future]
            try:
                result = future.result()
                if result:
                    results.append(result)
            except Exception as e:
                logger.debug(f"{ticker}: ã‚¨ãƒ©ãƒ¼ - {e}")
            finally:
                pbar.update(1)

# ã‚¹ãƒ†ãƒƒãƒ—4: çµæœã‚’DataFrameã«å¤‰æ›
if not results:
    logger.warning("âš ï¸  æ¡ä»¶ã«åˆã†éŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    return pd.DataFrame(), []

results_df = pd.DataFrame([asdict(r) for r in results])

# å„ªå…ˆåº¦ã§ã‚½ãƒ¼ãƒˆï¼ˆã‚¹ãƒ†ãƒ¼ã‚¸2 > ã‚¹ãƒ†ãƒ¼ã‚¸1ã€ã‚¹ã‚³ã‚¢é™é †ï¼‰
results_df['priority'] = results_df['current_stage'].apply(lambda x: 1 if x == 2 else 2)
results_df = results_df.sort_values(['priority', 'score'], ascending=[True, False])
results_df = results_df.drop('priority', axis=1)

# CSVå‡ºåŠ›
output_cols = ['ticker', 'current_stage', 'stage_name', 'stage_start_date', 
               'score', 'judgment', 'action', 'latest_price', 'ma50', 'rs_rating']
results_df[output_cols].to_csv(output_csv, index=False, encoding='utf-8-sig')

# çµ±è¨ˆ
stage2_count = len(results_df[results_df['current_stage'] == 2])
stage1_count = len(results_df[results_df['current_stage'] == 1])

logger.info("\n" + "="*70)
logger.info(f"âœ… åˆ†æå®Œäº†: {len(results)} ä»¶ã®æœ‰æœ›éŠ˜æŸ„ã‚’ç™ºè¦‹")
logger.info(f"   - ã‚¹ãƒ†ãƒ¼ã‚¸2ï¼ˆä¸Šæ˜‡æœŸï¼‰: {stage2_count} ä»¶")
logger.info(f"   - ã‚¹ãƒ†ãƒ¼ã‚¸1ï¼ˆåº•å›ºã‚æœŸï¼‰: {stage1_count} ä»¶")
logger.info(f"ğŸ“„ çµæœã‚’ {output_csv} ã«ä¿å­˜ã—ã¾ã—ãŸ")
if generate_charts:
    logger.info(f"ğŸ–¼ï¸  ãƒãƒ£ãƒ¼ãƒˆç”»åƒã‚’ {output_dir}/ ã«ä¿å­˜ã—ã¾ã—ãŸ")
logger.info("="*70 + "\n")

return results_df, results
```

# ============================================================================

# 9. Web APIç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

# ============================================================================

def get_analysis_summary(results: List[AnalysisResult]) -> Dict:
â€œâ€â€œåˆ†æçµæœã®ã‚µãƒãƒªãƒ¼ã‚’JSONå½¢å¼ã§è¿”ã™â€â€â€
if not results:
return {â€œstatusâ€: â€œno_resultsâ€, â€œcountâ€: 0}

```
stage2_tickers = [r.ticker for r in results if r.current_stage == 2]
stage1_tickers = [r.ticker for r in results if r.current_stage == 1]

high_score_tickers = [r.ticker for r in results if r.score >= 75]

return {
    "status": "success",
    "total_count": len(results),
    "stage2_count": len(stage2_tickers),
    "stage1_count": len(stage1_tickers),
    "high_score_count": len(high_score_tickers),
    "stage2_tickers": stage2_tickers[:10],  # ä¸Šä½10ä»¶
    "stage1_tickers": stage1_tickers[:10],
    "high_score_tickers": high_score_tickers[:10],
    "timestamp": datetime.now().isoformat()
}
```

# ============================================================================

# 10. ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ

# ============================================================================

if **name** == â€˜**main**â€™:
import argparse

```
parser = argparse.ArgumentParser(description='çµ±åˆæ ªå¼åˆ†æã‚·ã‚¹ãƒ†ãƒ ')
parser.add_argument('--max-tickers', type=int, default=50, help='å‡¦ç†ã™ã‚‹æœ€å¤§éŠ˜æŸ„æ•°')
parser.add_argument('--workers', type=int, default=4, help='ä¸¦åˆ—å‡¦ç†ã®ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°')
parser.add_argument('--charts', action='store_true', help='ãƒãƒ£ãƒ¼ãƒˆç”»åƒã‚’ç”Ÿæˆ')
parser.add_argument('--use-existing', action='store_true', help='æ—¢å­˜ã®stock.csvã‚’ä½¿ç”¨')
parser.add_argument('--output-dir', default='stage1or2', help='ãƒãƒ£ãƒ¼ãƒˆå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
parser.add_argument('--output-csv', default='stage1or2.csv', help='çµæœCSVå‡ºåŠ›ãƒ‘ã‚¹')

args = parser.parse_args()

# åˆ†æå®Ÿè¡Œ
df_results, results_list = run_full_analysis(
    use_existing_tickers=args.use_existing,
    max_tickers=args.max_tickers,
    max_workers=args.workers,
    generate_charts=args.charts,
    output_dir=args.output_dir,
    output_csv=args.output_csv
)

# ã‚µãƒãƒªãƒ¼è¡¨ç¤º
if results_list:
    summary = get_analysis_summary(results_list)
    print("\nğŸ“Š åˆ†æã‚µãƒãƒªãƒ¼:")
    print(json.dumps(summary, indent=2, ensure_ascii=False))
```